# -*- coding: utf-8 -*-
"""imageforensic.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1v3rwX0fecd0KDzLcjvTeC8mFvebOaF-X
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score
from tensorflow.keras.applications import ResNet50, EfficientNetB0
from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, GlobalAveragePooling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping
import os

image_dimensions = {'height': 256, 'width': 256, 'channels': 3}

dataGenerator = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    brightness_range=[0.8, 1.2],
    horizontal_flip=True,
    zoom_range=0.2
)

train_generator = dataGenerator.flow_from_directory(
    '/content/drive/MyDrive/Data Set 1/Data Set 1/train',
    target_size=(256, 256),
    batch_size=32,
    class_mode='binary'
)

valid_generator = dataGenerator.flow_from_directory(
    '/content/drive/MyDrive/Data Set 1/Data Set 1/validation',
    target_size=(256, 256),
    batch_size=32,
    class_mode='binary'
)

test_generator = dataGenerator.flow_from_directory(
    '/content/drive/MyDrive/Data Set 1/Data Set 1/test',
    target_size=(256, 256),
    batch_size=32,
    class_mode='binary'
)

class_weights = {0: 1.5, 1: 1.0}

epochs = 20
checkpoint = ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_accuracy', mode='max')
lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7)
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

def create_model(base_model, name):
    base_model.trainable = False
    inputs = Input(shape=(image_dimensions['height'], image_dimensions['width'], image_dimensions['channels']))
    x = base_model(inputs, training=False)
    x = GlobalAveragePooling2D()(x)
    x = Dropout(0.5)(x)
    outputs = Dense(1, activation='sigmoid')(x)
    model = Model(inputs, outputs, name=name)
    model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])
    return model

models = {
    'Meso4': Meso4(learning_rate=0.0001).model,
    'ResNet50': create_model(ResNet50(weights='imagenet', include_top=False), 'ResNet50'),
    'EfficientNetB0': create_model(EfficientNetB0(weights='imagenet', include_top=False), 'EfficientNetB0')
}

results = {}
for model_name, model in models.items():
    print(f"\nTraining {model_name}...\n")
    history = model.fit(
        train_generator,
        validation_data=valid_generator,
        epochs=epochs,
        class_weight=class_weights,
        callbacks=[checkpoint, lr_scheduler, early_stopping]
    )


    test_loss, test_accuracy = model.evaluate(test_generator)
    results[model_name] = test_accuracy
    print(f"\nTest Accuracy for {model_name}: {test_accuracy:.4f}")


    model.save(f'{model_name}.h5')

print("accuracy")
for model_name, accuracy in results.items():
    print(f"{model_name}: {accuracy:.4f}")





